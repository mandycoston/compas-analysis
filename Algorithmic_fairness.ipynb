{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important part of building AI systems is taking the time to understand your data and formatting it for the algorithms. This is often called *preprocessing*. In notebook 1, we began to analyze and understand the data. In this notebook we will do so in a more methodical way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat = pd.read_csv(\"./compas-scores-two-years.csv\", index_col=0)\n",
    "n, p = dat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing steps may involve 1) dropping rows that do not meet our inclusion criteria, 2) dropping columns that are not useful for our task, or 3) changing the representation of columns so that our algorithms can handle the data. Let's first consider (1). We should be suspicious of cases where the number of days between arrest date and charge date, *days_b_screening_arrest*, is more than 30. How many of these cases are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "735"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat[(dat.days_b_screening_arrest < -30) | (dat.days_b_screening_arrest > 30)].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is likely a data quality issue for most of these cases. Therefore we will drop these rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat = dat[(dat.days_b_screening_arrest >= -30) & (dat.days_b_screening_arrest <= 30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6172, 52)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing data is a common problem when using real-world data. How common is missing data for COMPASS?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name                          0\n",
       "first                         0\n",
       "last                          0\n",
       "compas_screening_date         0\n",
       "sex                           0\n",
       "dob                           0\n",
       "age                           0\n",
       "age_cat                       0\n",
       "race                          0\n",
       "juv_fel_count                 0\n",
       "decile_score                  0\n",
       "juv_misd_count                0\n",
       "juv_other_count               0\n",
       "priors_count                  0\n",
       "days_b_screening_arrest       0\n",
       "c_jail_in                     0\n",
       "c_jail_out                    0\n",
       "c_case_number                 0\n",
       "c_offense_date              784\n",
       "c_arrest_date              5388\n",
       "c_days_from_compas            0\n",
       "c_charge_degree               0\n",
       "c_charge_desc                 5\n",
       "is_recid                      0\n",
       "r_case_number              3182\n",
       "r_charge_degree            3182\n",
       "r_days_from_arrest         4175\n",
       "r_offense_date             3182\n",
       "r_charge_desc              3228\n",
       "r_jail_in                  4175\n",
       "r_jail_out                 4175\n",
       "violent_recid              6172\n",
       "is_violent_recid              0\n",
       "vr_case_number             5480\n",
       "vr_charge_degree           5480\n",
       "vr_offense_date            5480\n",
       "vr_charge_desc             5480\n",
       "type_of_assessment            0\n",
       "decile_score.1                0\n",
       "score_text                    0\n",
       "screening_date                0\n",
       "v_type_of_assessment          0\n",
       "v_decile_score                0\n",
       "v_score_text                  0\n",
       "v_screening_date              0\n",
       "in_custody                    0\n",
       "out_custody                   0\n",
       "priors_count.1                0\n",
       "start                         0\n",
       "end                           0\n",
       "event                         0\n",
       "two_year_recid                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This show that all rows have age but 3182 rows are missing r_charge_degree. Sometimes one would drop rows with missing values or impute (fill them in) by using the column average. Before we try either approach, let's first eliminate columns that are not useful as predictors in our model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider (2): which columns do we want to include as predictors in our model? Some features, like name or arrest date, are not useful for our task; we should drop these. However, we may later be interested in using these columns for visualizations or analyses: for instance we could ask how risk scores have changed over time as a function of COMPAS screening date. So let's leave *dat* as a dataframe that contains all our information and we'll create a new variable *X* that has the columns we want to use in our model.\n",
    "\n",
    "The columns that may be informative in predicting who will recommit a crime are the following columns:\n",
    "- Severity of the current crime: *c_charge_degree*\n",
    "- history of crime: *priors_count*, *juv_fel_count*, *juv_misd_count*, *juv_other_count*\n",
    "- demographic information: *age*, *race*, *sex*, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = dat[['c_charge_degree', 'priors_count', 'juv_fel_count', 'juv_misd_count', 'juv_other_count', 'age', 'race', 'sex']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** Create the outcome variable Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** Now let's check again whether any of our rows have missing values. <span style=\"color:red\">ADD</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's consider (3): the representation of each column. What is the type of each variable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c_charge_degree    object\n",
       "priors_count        int64\n",
       "juv_fel_count       int64\n",
       "juv_misd_count      int64\n",
       "juv_other_count     int64\n",
       "age                 int64\n",
       "race               object\n",
       "sex                object\n",
       "dtype: object"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*object* is the pandas data type (dtype) for *string* which is a string of text. Our machine learning algorithms however expect all variables to be numeric. We will need to convert the *object* dtypes to numeric (like *int64*). The most straightforward way to do this is to convert each column to multipe *dummy* columns. \n",
    "\n",
    "**TODO** Let's see how many values each object column has and how many occurences of each value there are in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "African-American    3175\n",
       "Caucasian           2103\n",
       "Hispanic             509\n",
       "Other                343\n",
       "Asian                 31\n",
       "Native American       11\n",
       "Name: race, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.race.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may cause problems to have a column with mostly zeros, so to avoid that, let's group 'Asian' and 'Native American' into 'Other'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X['race_Other'] = X['race_Other'] + X['race_Asian'] + X['race_Native American']\n",
    "X = X.drop(['race_Asian', 'race_Native American'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save this pandas dataframe to a CSV for future use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X.to_csv(\"X_pandas.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert it to a numpy matrix, which is required for the algorithms. Save dat, X, Y to csv for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X.values\n",
    "Y = Y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('X.csv', X)\n",
    "np.savetxt('y.csv', Y)\n",
    "dat.to_csv(\"dat.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will train a classifier to predict recidivism. We will analyze how these classifiers perform in terms of accuracy and fairness metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b6d353ab7df2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.loadtxt(\"X.csv\")\n",
    "y = np.loadtxt(\"y.csv\")\n",
    "X_pandas = pd.read_csv(\"X_pandas.csv\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "First we will partition our data into three sets: training and test sets.  We will use the training set to build our models. We will use the test set to evaluate how well our models perform. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set random seed for reproducibility\n",
    "seed = 20\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first train a logistic regression classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100000, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=10000,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(C=100000, max_iter=10000, solver = \"lbfgs\")\n",
    "logreg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is 0.6914\n"
     ]
    }
   ],
   "source": [
    "print(\"The accuracy is {0:.4f}\".format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model for future use using Python's object serialization package *pickle*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(logreg, open(\"logreg.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a vector of predicted labels. Each predicted label is either 0 (if the algorithm thinks the person will not recommit a crime) or 1 (if the algorithm thinks the person will recommit a crime). We can imagine a decision-making process where people who get a predicted label = 1 are denied pre-trial release and peopple who get a predicted label = 0 are released pre-trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_train = logreg.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save two files: 1) for training data and 2) for test data. Each file should contain the features (X), true label, and predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = np.hstack((X_train, np.expand_dims(y_train, axis=1), np.expand_dims(y_pred_train, axis=1)))\n",
    "test = np.hstack((X_test, np.expand_dims(y_test, axis=1), np.expand_dims(y_pred, axis=1)))\n",
    "np.savetxt('train.csv', train)\n",
    "np.savetxt('test.csv', test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interested in analyzing how are algorithms assigns decision based on attributes like race or gender since we want to analyze whether the algorithm is unfair.  \n",
    "\n",
    "Create a mapping to find the column location of each variable. This is needed since NumPy doesn't maintain the column labels as strings (only as numbers). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_map = list(X_pandas.columns)[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create boolean vectors indicating membership in each race or gender group. \n",
    "\n",
    "**TODO** Finish for race_Caucasian, race_Hispanic, and race_Other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "males = X_test[:,feat_map.index('sex_Male')] == 1\n",
    "afr_am = X_test[:,feat_map.index('race_African-American')] == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discrimination\n",
    "\n",
    "If we are going to let an algorithm make an important decision like who gets pre-trial release, we want to make sure the algorithm is accurate and also free from discrimination. But what does discrimination mean especially in the case of an algorithm? How might you define discrimination? Can you give some examples?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discrimination is typically tied to a *protected attribute* such as race or gender i.e. we argue that there is discrimination on the basis of the protected attribbute. \n",
    "\n",
    "Two common definitions of discrimination are **disparate impact** and **disparate treatment**. Disparate *treatment* refers to a process that treats individuals differently based on a demographic attribute. For instance, if a school had a policy that admitted men with a GPA of 3.0 or higher but only admitted women with a GPA of 3.5 or higher, this would be disparate treatment. This explicit notion of discrimination is commonly what people think of as discrimination.\n",
    "\n",
    "But there's another form of discrimination. Disparate *impact* refers to implicit discrimination, where a seemingly neutral policy leads to disparate outcomes in demographic groups. For instance, if a school had a policy that admitted football players with a GPA of 2.5 or higher but only admitted non-football players with a GPA of 3.5 or higher, then this would be disparate impact. The policy doesn't explicitly use the protected attribute gender, but the policy has the effect of allowing in more men with lower GPA's than women.\n",
    "\n",
    "What would disparate impact and disparate treatment look like in the case of our pre-trial release algorithm? Can you give examples of policies that would be described as having disparate impact or disparate treatment? Do you think one is more problematic than the other?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fairness\n",
    "\n",
    "Many people argue that a process is fair when it is free of discrimination, and above we considered some definitions of discrimination. We can also directly define fairness. \n",
    "\n",
    "## Demographic parity\n",
    "\n",
    "Demographic parity is a fairness concept that requires that the probability of an outcome be the same for two demographic groups. As an example, consider an algorithm determining loan approvals and consider that we are concerned about gender discrimination. The algorithm would not satisfy demographic parity if the probability of loan approval for women is 0.3 but the probability of loan approval for men is 0.8. \n",
    "\n",
    "Is it possible to have demographic parity and disparate impact? What about demographic parity and disparate treatment?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does our logistic regression classifier satisfy demographic parity with respect to race or gender? \n",
    "**TODO** Compute the means for the other race groups and gender groups. Compare the differences. How large of a difference do you think we should accept under the notion of demographic parity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression denies pre-trial release to 51.6% of African-Americans\n"
     ]
    }
   ],
   "source": [
    "afr_am_mean = y_pred[afr_am].mean()\n",
    "print(\"Logistic regression denies pre-trial release to {0:.1f}% of African-Americans\".format(afr_am_mean*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equalized Odds / Equal False Positive and True Positive Rates\n",
    "\n",
    "One might argue that it is fair that women are released more often than men if in fact women are less likely to recommit a crime. Then, one could take into account the *true* label in our fairness metrics. We could compare the probability that a woman who did not recidivate would be detained to the probability that a man who did not recidivate would be detained. These quantities are known as the false positive rates.\n",
    "\n",
    "**TODO** Compute the false positive rate for men and compare to the false positive rate for women."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fem_fpr = y_pred[(X_test[:,feat_map.index('sex_Female')] == 1) & (y_test==0)].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should also consider the true positive rate: the probability that a person who will recidivate would be detained. \n",
    "\n",
    "**TODO** Compute the false negative rates for men and women. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Equalized odds** The fairness goal of equalized odds requires that the true positive and false positive rates be the same for our protected attributes. Why do (or don't) you think this makes sense as a notion of fairness?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** Repeat the equalized odds analysis for race. Does our logistic regression classifier satisfy equalized odds?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration\n",
    "\n",
    "We will consider another metric that is a function of the predicted probabilities (as opposed to the predicted labels as we have considered so far). Our model is well-calibrated if the average recidivism rate for a group of people who get a predicted probability of x% is x%. We can plot a calibration curve to analyze this. The predicted probabilities range from 0 to 1, and we can split this up into ten bins: 0 to 0.1, 0.1 to 0.2, 0.2 to 0.3, and so on. On the x-axis, we plot the average of the bin (0.05, 0.15, etc) and on the y-axis we plot the average observed outcome for people who received a predicted probability in that bin.\n",
    "\n",
    "Note the people sometimes use *score* to refer to predicted probability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get vector of scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_score = logreg.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign each row to a bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_score_bins = np.where(y_score <= 0.1, 1, \\\n",
    "                        np.where(y_score <= 0.2, 2,\\\n",
    "                                 np.where(y_score <= 0.3, 3, \\\n",
    "                                          np.where(y_score <= 0.4, 4, \\\n",
    "                                                   np.where(y_score <= 0.5, 5, \\\n",
    "                                                            np.where(y_score <= 0.6, 6, \\\n",
    "                                                                    np.where(y_score <= 0.7, 7, \\\n",
    "                                                                              np.where(y_score <= 0.8, 8, \\\n",
    "                                                                                       np.where(y_score <= 0.9, 9, 10)))))))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute average label outcome for each bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_outcome = []\n",
    "for b in range(1,11):\n",
    "    avg = y_test[y_score_bins == b].mean()\n",
    "    avg_outcome.append(avg)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_score = [x * 0.01 for x in range(5, 100, 10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot calibration curve: avg_score against avg_outcome. I plot a solid reference line. A better calibration model will more closely track the reference y=x line. **TODO** Why is the y=x line our reference? How well is the model calibrated? Why do you think the first point is the farthest from the reference line?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x12e37f4a8>]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCncRET+kcBcR8UMKdxERP/T/Adg4uIhI7VyFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12e37f438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(avg_score, avg_outcome)\n",
    "plt.plot([0,1], [0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** Compute three calibration curves: one for each race. Is the model well-calibrated by race? It may be easiest to assess this if you plot all curves on one plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many researchers work on developing fair classifiers. In this notebook we will train some of these methods and analyze how they perform. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How might you try to make the classifier we built last time more fair? Would you try to change the data or maybe adjust the predictions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fairness Methods\n",
    " \n",
    " Methods for achieving algorithmic fairness fall into one of three categories:\n",
    " - Pre-processing\n",
    " - In-processing\n",
    " - Post-processing\n",
    " \n",
    " ## Pre-processing\n",
    " \n",
    " Pre-processing methods change the data in order to encourage the algorithm to be more fair. For instance we saw that African-Americans had a higher base rate of recidivism than Caucasians. Maybe if we changed the data so that the base rates looked equal (by for instance reweighing the training data), then the algorithm would learn a more fair classification. \n",
    " \n",
    " Pre-processing is method agnostic, but it makes no guarantee about how fair the resulting algorithm will be.\n",
    " \n",
    " ## In-processing\n",
    " \n",
    " In-processing methods change the actual learning procedure for the model. Most models are learned via an optimization; in-processing methods often constrain that optimization to a *fair* subspace.\n",
    " \n",
    " In-processing methods are not method agnostic, so they do not generalize well, but you can get fairness guarantees.\n",
    " \n",
    " ## Post-processing\n",
    " \n",
    " Post-processing methods take the predictions of any algorithm and adjust them to be more fair. For instance if our algorithm releases 50% of Caucasians but only 30% of African-Americans, then a most processing method could try to achieve demographic parity by randomly releasing 30% of African-Americans who otherwise would have been detained. How would this achieve demographic parity? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual we will import pandas and numpy. We also need to import an optimization package cvxpy. And we will import the fair methods from folders in this directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cvxpy as cvx\n",
    "from equalized_odds_and_calibration.eq_odds import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.loadtxt(\"train.csv\")\n",
    "test = np.loadtxt(\"test.csv\")\n",
    "X_pandas = pd.read_csv(\"X_pandas.csv\")\n",
    "feat_map = list(X_pandas.columns)[1:]\n",
    "feat_map.append(\"label\")\n",
    "feat_map.append(\"prediction\")\n",
    "X_train = train[:,:-2]\n",
    "y_train = train[:,-2]\n",
    "X_test = test[:, :-2]\n",
    "y_test = test[:,-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reweighing to balance base rates\n",
    "\n",
    "First we will experiment with a pre-processing method that reweighs our training data to balance the base rate. In our first notebook we calculated the base rates and saw they were different. Now that we have partitioned the data into training and test sets, let's recompute the base rates on the test and train partitions. They should be able the same as before but may be a little different based on the randomization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The recidivism base rate for Caucasian defendants is 0.400.\n",
      "The recidivism base rate for African-American defendants is 0.518.\n"
     ]
    }
   ],
   "source": [
    "recid_rate_cauc = y_train[train[:,feat_map.index('race_Caucasian')]==1].mean()\n",
    "print(\"The recidivism base rate for Caucasian defendants is {0:.3f}.\".format(recid_rate_cauc))\n",
    "recid_rate_afr_am = y_train[train[:,feat_map.index('race_African-American')]==1].mean()\n",
    "print(\"The recidivism base rate for African-American defendants is {0:.3f}.\".format(recid_rate_afr_am))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_afr_am = train[:, feat_map.index('race_African-American')].mean()\n",
    "perc_cauc = train[:, feat_map.index('race_Caucasian')].mean()\n",
    "recid_rate_all = y_train.mean()\n",
    "\n",
    "afr_am_pos_dummy = np.logical_and(train[:,feat_map.index('race_African-American')] ==1,\\\n",
    "                 y_train ==1)\n",
    "\n",
    "afr_am_neg_dummy = np.logical_and(train[:,feat_map.index('race_African-American')] ==1,\\\n",
    "                 y_train ==0)\n",
    "\n",
    "cauc_pos_dummy = np.logical_and(train[:,feat_map.index('race_Caucasian')] ==1,\\\n",
    "                 y_train ==1)\n",
    "\n",
    "cauc_neg_dummy = np.logical_and(train[:,feat_map.index('race_Caucasian')] ==1,\\\n",
    "                 y_train ==0)\n",
    "\n",
    "w_afr_am_pos = perc_afr_am * recid_rate_all \\\n",
    "/ np.logical_and(train[:,feat_map.index('race_African-American')] ==1,\\\n",
    "                 train[:,-2] ==1,).mean()\n",
    "\n",
    "w_afr_am_neg = perc_afr_am * (1-recid_rate_all) \\\n",
    "/ np.logical_and(train[:,feat_map.index('race_African-American')] ==1,\\\n",
    "                 train[:,-2] ==0,).mean()\n",
    "\n",
    "w_cauc_pos = perc_cauc * recid_rate_all \\\n",
    "/ np.logical_and(train[:,feat_map.index('race_Caucasian')] ==1,\\\n",
    "                 train[:,-2] ==1,).mean()\n",
    "\n",
    "w_cauc_neg = perc_cauc * (1-recid_rate_all) \\\n",
    "/ np.logical_and(train[:,feat_map.index('race_Caucasian')] ==1,\\\n",
    "                 train[:,-2] ==0,).mean()\n",
    "\n",
    "w = w_cauc_neg * np.logical_and(train[:,feat_map.index('race_Caucasian')] ==1,\\\n",
    "                 train[:,-2] ==0,) + \\\n",
    "w_cauc_pos * np.logical_and(train[:,feat_map.index('race_Caucasian')] ==1,\\\n",
    "                 train[:,-2] ==1,) + \\\n",
    "w_afr_am_neg * np.logical_and(train[:,feat_map.index('race_African-American')] ==1,\\\n",
    "                 train[:,-2] ==0,) + \\\n",
    "w_afr_am_pos * np.logical_and(train[:,feat_map.index('race_African-American')] ==1,\\\n",
    "                 train[:,-2] ==1,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate reweighed base rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "afr_am_rate_weighed = w[afr_am_pos_dummy].sum()/ \\\n",
    "w[train[:,feat_map.index('race_African-American')]==1].sum()\n",
    "\n",
    "cauc_rate_weighed = w[cauc_pos_dummy].sum()/ \\\n",
    "w[train[:,feat_map.index('race_Caucasian')]==1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4574669187145558"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cauc_rate_weighed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4574669187145557"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "afr_am_rate_weighed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use the weights to learn a new logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100000, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=10000,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_reweigh = LogisticRegression(C=100000, max_iter=10000, solver = \"lbfgs\")\n",
    "logreg_reweigh.fit(X_train,Y, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you compute the accuracy and the race-specific false positive and false negative rates (like we did in the last notebook)? *Hint* the FPR for African-Americans is given as an example below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPR for African-American after reweighing is 0.1786\n"
     ]
    }
   ],
   "source": [
    "y_pred = logreg_reweigh.predict(test[:, :-2])\n",
    "y_lab = y_pred.round()\n",
    "fpr_afr_am_reweigh = y_lab[np.logical_and(test[:, feat_map.index('race_African-American')]==1, \\\n",
    "                                          test[:, -2] == 0)].mean()\n",
    "print(\"FPR for African-American after reweighing is {0:.4f}\".format(fpr_afr_am_reweigh))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does reweighing help achieve equalized odds? Why or why not? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-processing for Equalized Odds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will explore a method developed by Moritz Hardt et al (https://arxiv.org/pdf/1610.02413.pdf) that uses post-processing techniques to achieve equalized odds. \n",
    "\n",
    "Their methods require a Model data structure that takes two inputs: 1) a matrix of the algorithm predictions and 2) a matrix of the true labels. We have to create such a Model object for each demographic group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['priors_count',\n",
       " 'juv_fel_count',\n",
       " 'juv_misd_count',\n",
       " 'juv_other_count',\n",
       " 'age',\n",
       " 'c_charge_degree_F',\n",
       " 'c_charge_degree_M',\n",
       " 'race_African-American',\n",
       " 'race_Caucasian',\n",
       " 'race_Hispanic',\n",
       " 'race_Other',\n",
       " 'sex_Female',\n",
       " 'sex_Male',\n",
       " 'label',\n",
       " 'prediction']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3703, 15)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "afr_am_train = train[train[:,feat_map.index(\"race_African-American\")] == 1]\n",
    "cauc_train = train[train[:,feat_map.index(\"race_Caucasian\")] == 1]\n",
    "afr_am_test = test[test[:,feat_map.index(\"race_African-American\")] == 1]\n",
    "cauc_test = test[test[:,feat_map.index(\"race_Caucasian\")] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_map.index(\"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_afr_am_train = Model(afr_am_train[:, feat_map.index(\"prediction\")], afr_am_train[:, feat_map.index(\"label\")])\n",
    "model_cauc_train = Model(cauc_train[:, feat_map.index(\"prediction\")], cauc_train[:, feat_map.index(\"label\")])\n",
    "model_afr_am_test = Model(afr_am_test[:, feat_map.index(\"prediction\")], afr_am_test[:, feat_map.index(\"label\")])\n",
    "model_cauc_test = Model(cauc_test[:, feat_map.index(\"prediction\")], cauc_test[:, feat_map.index(\"label\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check that we have done this properly, we can print the models. This shows us the accuracy, FPR, FNR, base rate and mean prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy:\t0.685\n",
       "F.P. cost:\t0.309\n",
       "F.N. cost:\t0.321\n",
       "Base rate:\t0.518\n",
       "Avg. score:\t0.501"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_afr_am_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy:\t0.665\n",
       "F.P. cost:\t0.152\n",
       "F.N. cost:\t0.610\n",
       "Base rate:\t0.400\n",
       "Avg. score:\t0.247"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cauc_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's call the method for post-processing. This method gives us mixing rates that tell us how to randomly resample predicted labels to equalize false positive rates and false negative rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_, _, mixing_rates = Model.eq_odds(model_afr_am_train, model_cauc_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can correct the predictions using these mixing rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_afr_am_train_corrected, model_cauc_train_corrected = Model.eq_odds(model_afr_am_train, model_cauc_train, mixing_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy:\t0.612\n",
       "F.P. cost:\t0.185\n",
       "F.N. cost:\t0.577\n",
       "Base rate:\t0.518\n",
       "Avg. score:\t0.308"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_afr_am_train_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy:\t0.649\n",
       "F.P. cost:\t0.193\n",
       "F.N. cost:\t0.587\n",
       "Base rate:\t0.400\n",
       "Avg. score:\t0.281"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cauc_train_corrected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did this achieve equalized odds? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should evaluate how the mixing performs on the test partition. Why do we need to do this? Should we get new mixing rates on the test partition or use the mixing rates learned from the train partition?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_afr_am_test_corrected, model_cauc_test_corrected = Model.eq_odds(model_afr_am_test, model_cauc_test, mixing_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy:\t0.672\n",
       "F.P. cost:\t0.178\n",
       "F.N. cost:\t0.576\n",
       "Base rate:\t0.378\n",
       "Avg. score:\t0.271"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cauc_test_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy:\t0.592\n",
       "F.P. cost:\t0.207\n",
       "F.N. cost:\t0.585\n",
       "Base rate:\t0.531\n",
       "Avg. score:\t0.318"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_afr_am_test_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy:\t0.691\n",
       "F.P. cost:\t0.136\n",
       "F.N. cost:\t0.594\n",
       "Base rate:\t0.378\n",
       "Avg. score:\t0.238"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cauc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy:\t0.688\n",
       "F.P. cost:\t0.316\n",
       "F.N. cost:\t0.307\n",
       "Base rate:\t0.531\n",
       "Avg. score:\t0.516"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_afr_am_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What notion of fairness does this method achieve, if any? What is the effect of this method on the accuracy? Do you think we should use this method for our pre-trial bail application?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
