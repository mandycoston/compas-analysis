{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important part of building AI systems is taking the time to understand your data and formatting it for the algorithms. This is often called *preprocessing*. In notebook 1, we began to analyze and understand the data. In this notebook we will do so in a more methodical way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat = pd.read_csv(\"./compas-scores-two-years.csv\", index_col=0)\n",
    "n, p = dat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing steps may involve 1) dropping rows that do not meet our inclusion criteria, 2) dropping columns that are not useful for our task, or 3) changing the representation of columns so that our algorithms can handle the data. Let's first consider (1). We should be suspicious of cases where the number of days between arrest date and charge date, *days_b_screening_arrest*, is more than 30. How many of these cases are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "735"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat[(dat.days_b_screening_arrest < -30) | (dat.days_b_screening_arrest > 30)].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is likely a data quality issue for most of these cases. Therefore we will drop these rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = dat[(dat.days_b_screening_arrest >= -30) & (dat.days_b_screening_arrest <= 30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6172, 52)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing data is a common problem when using real-world data. How common is missing data for COMPASS?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name                          0\n",
       "first                         0\n",
       "last                          0\n",
       "compas_screening_date         0\n",
       "sex                           0\n",
       "dob                           0\n",
       "age                           0\n",
       "age_cat                       0\n",
       "race                          0\n",
       "juv_fel_count                 0\n",
       "decile_score                  0\n",
       "juv_misd_count                0\n",
       "juv_other_count               0\n",
       "priors_count                  0\n",
       "days_b_screening_arrest       0\n",
       "c_jail_in                     0\n",
       "c_jail_out                    0\n",
       "c_case_number                 0\n",
       "c_offense_date              784\n",
       "c_arrest_date              5388\n",
       "c_days_from_compas            0\n",
       "c_charge_degree               0\n",
       "c_charge_desc                 5\n",
       "is_recid                      0\n",
       "r_case_number              3182\n",
       "r_charge_degree            3182\n",
       "r_days_from_arrest         4175\n",
       "r_offense_date             3182\n",
       "r_charge_desc              3228\n",
       "r_jail_in                  4175\n",
       "r_jail_out                 4175\n",
       "violent_recid              6172\n",
       "is_violent_recid              0\n",
       "vr_case_number             5480\n",
       "vr_charge_degree           5480\n",
       "vr_offense_date            5480\n",
       "vr_charge_desc             5480\n",
       "type_of_assessment            0\n",
       "decile_score.1                0\n",
       "score_text                    0\n",
       "screening_date                0\n",
       "v_type_of_assessment          0\n",
       "v_decile_score                0\n",
       "v_score_text                  0\n",
       "v_screening_date              0\n",
       "in_custody                    0\n",
       "out_custody                   0\n",
       "priors_count.1                0\n",
       "start                         0\n",
       "end                           0\n",
       "event                         0\n",
       "two_year_recid                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This show that all rows have age but 3182 rows are missing r_charge_degree. Sometimes one would drop rows with missing values or impute (fill them in) by using the column average. Before we try either approach, let's first eliminate columns that are not useful as predictors in our model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider (2): which columns do we want to include as predictors in our model? Some features, like name or arrest date, are not useful for our task; we should drop these. However, we may later be interested in using these columns for visualizations or analyses: for instance we could ask how risk scores have changed over time as a function of COMPAS screening date. So let's leave *dat* as a dataframe that contains all our information and we'll create a new variable *X* that has the columns we want to use in our model.\n",
    "\n",
    "The columns that may be informative in predicting who will recommit a crime are the following columns:\n",
    "- Severity of the current crime: *c_charge_degree*\n",
    "- history of crime: *priors_count*, *juv_fel_count*, *juv_misd_count*, *juv_other_count*\n",
    "- demographic information: *age*, *race*, *sex*, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dat[['c_charge_degree', 'priors_count', 'juv_fel_count', 'juv_misd_count', 'juv_other_count', 'age', 'race', 'sex']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** Create the outcome variable Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** Now let's check again whether any of our rows have missing values. <span style=\"color:red\">ADD</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's consider (3): the representation of each column. What is the type of each variable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c_charge_degree    object\n",
       "priors_count        int64\n",
       "juv_fel_count       int64\n",
       "juv_misd_count      int64\n",
       "juv_other_count     int64\n",
       "age                 int64\n",
       "race               object\n",
       "sex                object\n",
       "dtype: object"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*object* is the pandas data type (dtype) for *string* which is a string of text. Our machine learning algorithms however expect all variables to be numeric. We will need to convert the *object* dtypes to numeric (like *int64*). The most straightforward way to do this is to convert each column to multipe *dummy* columns. \n",
    "\n",
    "**TODO** Let's see how many values each object column has and how many occurences of each value there are in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "African-American    3175\n",
       "Caucasian           2103\n",
       "Hispanic             509\n",
       "Other                343\n",
       "Asian                 31\n",
       "Native American       11\n",
       "Name: race, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.race.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may cause problems to have a column with mostly zeros, so to avoid that, let's group 'Asian' and 'Native American' into 'Other'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X['race_Other'] = X['race_Other'] + X['race_Asian'] + X['race_Native American']\n",
    "X = X.drop(['race_Asian', 'race_Native American'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save this pandas dataframe to a CSV for future use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X.to_csv(\"X_pandas.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert it to a numpy matrix, which is required for the algorithms. Save dat, X, Y to csv for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.values\n",
    "Y = Y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('X.csv', X)\n",
    "np.savetxt('y.csv', Y)\n",
    "dat.to_csv(\"dat.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
