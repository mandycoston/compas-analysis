{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many researchers work on developing fair classifiers. In this notebook we will train some of these methods and analyze how they perform. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How might you try to make the classifier we built last time more fair? Would you try to change the data or maybe adjust the predictions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fairness Methods\n",
    " \n",
    " Methods for achieving algorithmic fairness fall into one of three categories:\n",
    " - Pre-processing\n",
    " - In-processing\n",
    " - Post-processing\n",
    " \n",
    " ## Pre-processing\n",
    " \n",
    " Pre-processing methods change the data in order to encourage the algorithm to be more fair. For instance we saw that African-Americans had a higher base rate of recidivism than Caucasians. Maybe if we changed the data so that the base rates looked equal (by for instance reweighing the training data), then the algorithm would learn a more fair classification. \n",
    " \n",
    " Pre-processing is method agnostic, but it makes no guarantee about how fair the resulting algorithm will be.\n",
    " \n",
    " ## In-processing\n",
    " \n",
    " In-processing methods change the actual learning procedure for the model. Most models are learned via an optimization; in-processing methods often constrain that optimization to a *fair* subspace.\n",
    " \n",
    " In-processing methods are not method agnostic, so they do not generalize well, but you can get fairness guarantees.\n",
    " \n",
    " ## Post-processing\n",
    " \n",
    " Post-processing methods take the predictions of any algorithm and adjust them to be more fair. For instance if our algorithm releases 50% of Caucasians but only 30% of African-Americans, then a most processing method could try to achieve demographic parity by randomly releasing 30% of African-Americans who otherwise would have been detained. How would this achieve demographic parity? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual we will import pandas and numpy. We also need to import an optimization package cvxpy. And we will import the fair methods from folders in this directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cvxpy as cvx\n",
    "from equalized_odds_and_calibration.eq_odds import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.loadtxt(\"train.csv\")\n",
    "test = np.loadtxt(\"test.csv\")\n",
    "X_pandas = pd.read_csv(\"X_pandas.csv\")\n",
    "feat_map = list(X_pandas.columns)[1:]\n",
    "feat_map.append(\"label\")\n",
    "feat_map.append(\"prediction\")\n",
    "X_train = train[:,:-2]\n",
    "y_train = train[:,-2]\n",
    "X_test = test[:, :-2]\n",
    "y_test = test[:,-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reweighing to balance base rates\n",
    "\n",
    "First we will experiment with a pre-processing method that reweighs our training data to balance the base rate. In our first notebook we calculated the base rates and saw they were different. Now that we have partitioned the data into training and test sets, let's recompute the base rates on the test and train partitions. They should be able the same as before but may be a little different based on the randomization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The recidivism base rate for Caucasian defendants is 0.400.\n",
      "The recidivism base rate for African-American defendants is 0.518.\n"
     ]
    }
   ],
   "source": [
    "recid_rate_cauc = y_train[train[:,feat_map.index('race_Caucasian')]==1].mean()\n",
    "print(\"The recidivism base rate for Caucasian defendants is {0:.3f}.\".format(recid_rate_cauc))\n",
    "recid_rate_afr_am = y_train[train[:,feat_map.index('race_African-American')]==1].mean()\n",
    "print(\"The recidivism base rate for African-American defendants is {0:.3f}.\".format(recid_rate_afr_am))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_afr_am = train[:, feat_map.index('race_African-American')].mean()\n",
    "perc_cauc = train[:, feat_map.index('race_Caucasian')].mean()\n",
    "recid_rate_all = y_train.mean()\n",
    "\n",
    "afr_am_pos_dummy = np.logical_and(train[:,feat_map.index('race_African-American')] ==1,\\\n",
    "                 y_train ==1)\n",
    "\n",
    "afr_am_neg_dummy = np.logical_and(train[:,feat_map.index('race_African-American')] ==1,\\\n",
    "                 y_train ==0)\n",
    "\n",
    "cauc_pos_dummy = np.logical_and(train[:,feat_map.index('race_Caucasian')] ==1,\\\n",
    "                 y_train ==1)\n",
    "\n",
    "cauc_neg_dummy = np.logical_and(train[:,feat_map.index('race_Caucasian')] ==1,\\\n",
    "                 y_train ==0)\n",
    "\n",
    "w_afr_am_pos = perc_afr_am * recid_rate_all \\\n",
    "/ np.logical_and(train[:,feat_map.index('race_African-American')] ==1,\\\n",
    "                 train[:,-2] ==1,).mean()\n",
    "\n",
    "w_afr_am_neg = perc_afr_am * (1-recid_rate_all) \\\n",
    "/ np.logical_and(train[:,feat_map.index('race_African-American')] ==1,\\\n",
    "                 train[:,-2] ==0,).mean()\n",
    "\n",
    "w_cauc_pos = perc_cauc * recid_rate_all \\\n",
    "/ np.logical_and(train[:,feat_map.index('race_Caucasian')] ==1,\\\n",
    "                 train[:,-2] ==1,).mean()\n",
    "\n",
    "w_cauc_neg = perc_cauc * (1-recid_rate_all) \\\n",
    "/ np.logical_and(train[:,feat_map.index('race_Caucasian')] ==1,\\\n",
    "                 train[:,-2] ==0,).mean()\n",
    "\n",
    "w = w_cauc_neg * np.logical_and(train[:,feat_map.index('race_Caucasian')] ==1,\\\n",
    "                 train[:,-2] ==0,) + \\\n",
    "w_cauc_pos * np.logical_and(train[:,feat_map.index('race_Caucasian')] ==1,\\\n",
    "                 train[:,-2] ==1,) + \\\n",
    "w_afr_am_neg * np.logical_and(train[:,feat_map.index('race_African-American')] ==1,\\\n",
    "                 train[:,-2] ==0,) + \\\n",
    "w_afr_am_pos * np.logical_and(train[:,feat_map.index('race_African-American')] ==1,\\\n",
    "                 train[:,-2] ==1,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate reweighed base rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "afr_am_rate_weighed = w[afr_am_pos_dummy].sum()/ \\\n",
    "w[train[:,feat_map.index('race_African-American')]==1].sum()\n",
    "\n",
    "cauc_rate_weighed = w[cauc_pos_dummy].sum()/ \\\n",
    "w[train[:,feat_map.index('race_Caucasian')]==1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4574669187145558"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cauc_rate_weighed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4574669187145557"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "afr_am_rate_weighed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use the weights to learn a new logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100000, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=10000,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_reweigh = LogisticRegression(C=100000, max_iter=10000, solver = \"lbfgs\")\n",
    "logreg_reweigh.fit(X_train,Y, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you compute the accuracy and the race-specific false positive and false negative rates (like we did in the last notebook)? *Hint* the FPR for African-Americans is given as an example below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPR for African-American after reweighing is 0.1786\n"
     ]
    }
   ],
   "source": [
    "y_pred = logreg_reweigh.predict(test[:, :-2])\n",
    "y_lab = y_pred.round()\n",
    "fpr_afr_am_reweigh = y_lab[np.logical_and(test[:, feat_map.index('race_African-American')]==1, \\\n",
    "                                          test[:, -2] == 0)].mean()\n",
    "print(\"FPR for African-American after reweighing is {0:.4f}\".format(fpr_afr_am_reweigh))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does reweighing help achieve equalized odds? Why or why not? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-processing for Equalized Odds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will explore a method developed by Moritz Hardt et al (https://arxiv.org/pdf/1610.02413.pdf) that uses post-processing techniques to achieve equalized odds. \n",
    "\n",
    "Their methods require a Model data structure that takes two inputs: 1) a matrix of the algorithm predictions and 2) a matrix of the true labels. We have to create such a Model object for each demographic group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['priors_count',\n",
       " 'juv_fel_count',\n",
       " 'juv_misd_count',\n",
       " 'juv_other_count',\n",
       " 'age',\n",
       " 'c_charge_degree_F',\n",
       " 'c_charge_degree_M',\n",
       " 'race_African-American',\n",
       " 'race_Caucasian',\n",
       " 'race_Hispanic',\n",
       " 'race_Other',\n",
       " 'sex_Female',\n",
       " 'sex_Male',\n",
       " 'label',\n",
       " 'prediction']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3703, 15)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "afr_am_train = train[train[:,feat_map.index(\"race_African-American\")] == 1]\n",
    "cauc_train = train[train[:,feat_map.index(\"race_Caucasian\")] == 1]\n",
    "afr_am_test = test[test[:,feat_map.index(\"race_African-American\")] == 1]\n",
    "cauc_test = test[test[:,feat_map.index(\"race_Caucasian\")] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_map.index(\"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_afr_am_train = Model(afr_am_train[:, feat_map.index(\"prediction\")], afr_am_train[:, feat_map.index(\"label\")])\n",
    "model_cauc_train = Model(cauc_train[:, feat_map.index(\"prediction\")], cauc_train[:, feat_map.index(\"label\")])\n",
    "model_afr_am_test = Model(afr_am_test[:, feat_map.index(\"prediction\")], afr_am_test[:, feat_map.index(\"label\")])\n",
    "model_cauc_test = Model(cauc_test[:, feat_map.index(\"prediction\")], cauc_test[:, feat_map.index(\"label\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check that we have done this properly, we can print the models. This shows us the accuracy, FPR, FNR, base rate and mean prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy:\t0.685\n",
       "F.P. cost:\t0.309\n",
       "F.N. cost:\t0.321\n",
       "Base rate:\t0.518\n",
       "Avg. score:\t0.501"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_afr_am_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy:\t0.665\n",
       "F.P. cost:\t0.152\n",
       "F.N. cost:\t0.610\n",
       "Base rate:\t0.400\n",
       "Avg. score:\t0.247"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cauc_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's call the method for post-processing. This method gives us mixing rates that tell us how to randomly resample predicted labels to equalize false positive rates and false negative rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_, _, mixing_rates = Model.eq_odds(model_afr_am_train, model_cauc_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can correct the predictions using these mixing rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_afr_am_train_corrected, model_cauc_train_corrected = Model.eq_odds(model_afr_am_train, model_cauc_train, mixing_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy:\t0.612\n",
       "F.P. cost:\t0.185\n",
       "F.N. cost:\t0.577\n",
       "Base rate:\t0.518\n",
       "Avg. score:\t0.308"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_afr_am_train_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy:\t0.649\n",
       "F.P. cost:\t0.193\n",
       "F.N. cost:\t0.587\n",
       "Base rate:\t0.400\n",
       "Avg. score:\t0.281"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cauc_train_corrected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did this achieve equalized odds? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should evaluate how the mixing performs on the test partition. Why do we need to do this? Should we get new mixing rates on the test partition or use the mixing rates learned from the train partition?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_afr_am_test_corrected, model_cauc_test_corrected = Model.eq_odds(model_afr_am_test, model_cauc_test, mixing_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy:\t0.672\n",
       "F.P. cost:\t0.178\n",
       "F.N. cost:\t0.576\n",
       "Base rate:\t0.378\n",
       "Avg. score:\t0.271"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cauc_test_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy:\t0.592\n",
       "F.P. cost:\t0.207\n",
       "F.N. cost:\t0.585\n",
       "Base rate:\t0.531\n",
       "Avg. score:\t0.318"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_afr_am_test_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy:\t0.691\n",
       "F.P. cost:\t0.136\n",
       "F.N. cost:\t0.594\n",
       "Base rate:\t0.378\n",
       "Avg. score:\t0.238"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cauc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy:\t0.688\n",
       "F.P. cost:\t0.316\n",
       "F.N. cost:\t0.307\n",
       "Base rate:\t0.531\n",
       "Avg. score:\t0.516"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_afr_am_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What notion of fairness does this method achieve, if any? What is the effect of this method on the accuracy? Do you think we should use this method for our pre-trial bail application?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
