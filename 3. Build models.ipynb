{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will train several classifiers as models to predict recidivism. We will analyze how these classifiers perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.loadtxt(\"X.csv\")\n",
    "y = np.loadtxt(\"y.csv\")\n",
    "X_pandas = pd.read_csv(\"X_pandas.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will partition our data into three sets: training, evaluation, and holdout. We will use the training set to build our models. We will use the evaluation set to evaluate how well our models perform. The holdout set is reserved for the end of the project; once we have tinkered with the models, we will see how well they perform on a fresh holdout set. Final conclusions should be based on analysis on the holdout set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set random seed for reproducibility\n",
    "seed = 20\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=seed)\n",
    "X_eval, X_hold, y_eval, y_hold = train_test_split(X_test, y_test, test_size=0.45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first train a logistic regression classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100000, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=10000,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(C=100000, max_iter=10000)\n",
    "logreg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is 0.6914\n"
     ]
    }
   ],
   "source": [
    "print(\"The accuracy is {0:.4f}\".format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a vector of predicted labels. Each predicted label is either 0 (if the algorithm thinks the person will not recommit a crime) or 1 (if the algorithm thinks the person will recommit a crime). We can imagine a decision-making process where people who get a predicted label = 1 are denied pre-trial release and peopple who get a predicted label = 0 are released pre-trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interested in analyzing how are algorithms assigns decision based on attributes like race or gender since we want to analyze whether the algorithm is unfair.  \n",
    "\n",
    "Create a mapping to find the column location of each variable. This is needed since NumPy doesn't maintain the column labels as strings (only as numbers). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_map = list(X_pandas.columns)[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create boolean vectors indicating membership in each race or gender group. \n",
    "\n",
    "**TODO** Finish for race_Caucasian, race_Hispanic, and race_Other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "males = X_test[:,feat_map.index('sex_Male')] == 1\n",
    "afr_am = X_test[:,feat_map.index('race_African-American')] == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fairness Metrics\n",
    "## Demographic parity\n",
    "\n",
    "Demographic parity is a fairness concept that requires that the probability of an outcome be the same for two demographic groups. As an example, consider an algorithm determining loan approvals and consider that we are concerned about gender discrimination. The algorithm would not satisfy demographic parity if the probability of loan approval for women is 0.3 but the probability of loan approval for men is 0.8. \n",
    "\n",
    "Does our logistic regression classifier satisfy demographic parity with respect to race or gender? \n",
    "**TODO** Compute the means for the other race groups and gender groups. Compare the differences. How large of a difference do you think we should accept under the notion of demographic parity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression denies pre-trial release to 51.6% of African-Americans\n"
     ]
    }
   ],
   "source": [
    "afr_am_mean = y_pred[afr_am].mean()\n",
    "print(\"Logistic regression denies pre-trial release to {0:.1f}% of African-Americans\".format(afr_am_mean*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equalized Odds / Equal False Positive and True Positive Rates\n",
    "\n",
    "One might argue that it is fair that women are released more often than men if in fact women are less likely to recommit a crime. Then, one could take into account the *true* label in our fairness metrics. We could compare the probability that a woman who did not recidivate would be detained to the probability that a man who did not recidivate would be detained. These quantities are known as the false positive rates.\n",
    "\n",
    "**TODO** Compute the false positive rate for men and compare to the false positive rate for women."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "fem_fpr = y_pred[(X_test[:,feat_map.index('sex_Female')] == 1) & (y_test==0)].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should also consider the true positive rate: the probability that a person who will recidivate would be detained. \n",
    "\n",
    "**TODO** Compute the false negative rates for men and women. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** Repeat the equalized odds analysis for race. Does our logistic regression classifier satisfy equalized odds?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration\n",
    "\n",
    "We will consider another metric that is a function of the predicted probabilities (as opposed to the predicted labels as we have considered so far). Our model is well-calibrated if the average recidivism rate for a group of people who get a predicted probability of x% is x%. We can plot a calibration curve to analyze this. The predicted probabilities range from 0 to 1, and we can split this up into ten bins: 0 to 0.1, 0.1 to 0.2, 0.2 to 0.3, and so on. On the x-axis, we plot the average of the bin (0.05, 0.15, etc) and on the y-axis we plot the average observed outcome for people who received a predicted probability in that bin.\n",
    "\n",
    "Note the people sometimes use *score* to refer to predicted probability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get vector of scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_score = logreg.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign each row to a bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score_bins = np.where(y_score <= 0.1, 1, \\\n",
    "                        np.where(y_score <= 0.2, 2,\\\n",
    "                                 np.where(y_score <= 0.3, 3, \\\n",
    "                                          np.where(y_score <= 0.4, 4, \\\n",
    "                                                   np.where(y_score <= 0.5, 5, \\\n",
    "                                                            np.where(y_score <= 0.6, 6, \\\n",
    "                                                                    np.where(y_score <= 0.7, 7, \\\n",
    "                                                                              np.where(y_score <= 0.8, 8, \\\n",
    "                                                                                       np.where(y_score <= 0.9, 9, 10)))))))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute average label outcome for each bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_outcome = []\n",
    "for b in range(1,11):\n",
    "    avg = y_test[y_score_bins == b].mean()\n",
    "    avg_outcome.append(avg)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_score = [x * 0.01 for x in range(5, 100, 10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot calibration curve: avg_score against avg_outcome. I plot a solid reference line. A better calibration model will more closely track the reference y=x line. **TODO** Why is the y=x line our reference? How well is the model calibrated? Why do you think the first point is the farthest from the reference line?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x12e37f4a8>]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCncRET+kcBcR8UMKdxERP/T/Adg4uIhI7VyFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12e37f438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(avg_score, avg_outcome)\n",
    "plt.plot([0,1], [0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** Compute calibration curve for ou"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
