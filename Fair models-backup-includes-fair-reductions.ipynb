{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many researchers work on developing fair classifiers. In this notebook we will train some of these methods and analyze how they perform. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How might you try to make the classifier we built last time more fair? Would you try to change the data or maybe adjust the predictions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fairness Methods\n",
    " \n",
    " Methods for achieving algorithmic fairness fall into one of three categories:\n",
    " - Pre-processing\n",
    " - In-processing\n",
    " - Post-processing\n",
    " \n",
    " ## Pre-processing\n",
    " \n",
    " Pre-processing methods change the data in order to encourage the algorithm to be more fair. For instance we saw that African-Americans had a higher base rate of recidivism than Caucasians. Maybe if we changed the data so that the base rates looked equal (by for instance reweighing the training data), then the algorithm would learn a more fair classification. \n",
    " \n",
    " Pre-processing is method agnostic, but it makes no guarantee about how fair the resulting algorithm will be.\n",
    " \n",
    " ## In-processing\n",
    " \n",
    " In-processing methods change the actual learning procedure for the model. Most models are learned via an optimization; in-processing methods often constrain that optimization to a *fair* subspace.\n",
    " \n",
    " In-processing methods are not method agnostic, so they do not generalize well, but you can get fairness guarantees.\n",
    " \n",
    " ## Post-processing\n",
    " \n",
    " Post-processing methods take the predictions of any algorithm and adjust them to be more fair. For instance if our algorithm releases 50% of Caucasians but only 30% of African-Americans, then a most processing method could try to achieve demographic parity by randomly releasing 30% of African-Americans who otherwise would have been detained. How would this achieve demographic parity? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual we will import pandas and numpy. We also need to import an optimization package cvxpy. And we will import the fair methods from folders in this directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cvxpy as cvx\n",
    "from equalized_odds_and_calibration.eq_odds import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.loadtxt(\"train.csv\")\n",
    "test = np.loadtxt(\"test.csv\")\n",
    "X_pandas = pd.read_csv(\"X_pandas.csv\")\n",
    "feat_map = list(X_pandas.columns)[1:]\n",
    "feat_map.append(\"label\")\n",
    "feat_map.append(\"prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-processing for Equalized Odds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will explore a method developed by Moritz Hardt et al (https://arxiv.org/pdf/1610.02413.pdf) that uses post-processing techniques to achieve equalized odds. \n",
    "\n",
    "Their methods require a Model data structure that takes two inputs: 1) a matrix of the algorithm predictions and 2) a matrix of the true labels. We have to create such a Model object for each demographic group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['priors_count',\n",
       " 'juv_fel_count',\n",
       " 'juv_misd_count',\n",
       " 'juv_other_count',\n",
       " 'age',\n",
       " 'c_charge_degree_F',\n",
       " 'c_charge_degree_M',\n",
       " 'race_African-American',\n",
       " 'race_Caucasian',\n",
       " 'race_Hispanic',\n",
       " 'race_Other',\n",
       " 'sex_Female',\n",
       " 'sex_Male',\n",
       " 'label',\n",
       " 'prediction']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3703, 15)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "afr_am_train = train[train[:,feat_map.index(\"race_African-American\")] == 1]\n",
    "cauc_train = train[train[:,feat_map.index(\"race_Caucasian\")] == 1]\n",
    "afr_am_test = test[test[:,feat_map.index(\"race_African-American\")] == 1]\n",
    "cauc_test = test[test[:,feat_map.index(\"race_Caucasian\")] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_map.index(\"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_afr_am_train = Model(afr_am_train[:, feat_map.index(\"prediction\")], afr_am_train[:, feat_map.index(\"label\")])\n",
    "model_cauc_train = Model(cauc_train[:, feat_map.index(\"prediction\")], cauc_train[:, feat_map.index(\"label\")])\n",
    "model_afr_am_test = Model(afr_am_test[:, feat_map.index(\"prediction\")], afr_am_test[:, feat_map.index(\"label\")])\n",
    "model_cauc_test = Model(cauc_test[:, feat_map.index(\"prediction\")], cauc_test[:, feat_map.index(\"label\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check that we have done this properly, we can print the models. This shows us the accuracy, FPR, FNR, base rate and mean prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy:\t0.685\n",
       "F.P. cost:\t0.309\n",
       "F.N. cost:\t0.321\n",
       "Base rate:\t0.518\n",
       "Avg. score:\t0.501"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_afr_am_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy:\t0.665\n",
       "F.P. cost:\t0.152\n",
       "F.N. cost:\t0.610\n",
       "Base rate:\t0.400\n",
       "Avg. score:\t0.247"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cauc_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's call the method for post-processing. This method gives us mixing rates that tell us how to randomly resample predicted labels to equalize false positive rates and false negative rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_, _, mixing_rates = Model.eq_odds(model_afr_am_train, model_cauc_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can correct the predictions using these mixing rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_afr_am_train_corrected, model_cauc_train_corrected = Model.eq_odds(model_afr_am_train, model_cauc_train, mixing_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy:\t0.612\n",
       "F.P. cost:\t0.185\n",
       "F.N. cost:\t0.577\n",
       "Base rate:\t0.518\n",
       "Avg. score:\t0.308"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_afr_am_train_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy:\t0.649\n",
       "F.P. cost:\t0.193\n",
       "F.N. cost:\t0.587\n",
       "Base rate:\t0.400\n",
       "Avg. score:\t0.281"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cauc_train_corrected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did this achieve equalized odds? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should evaluate how the mixing performs on the test partition. Why do we need to do this? Should we get new mixing rates on the test partition or use the mixing rates learned from the train partition?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_afr_am_test_corrected, model_cauc_test_corrected = Model.eq_odds(model_afr_am_test, model_cauc_test, mixing_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy:\t0.672\n",
       "F.P. cost:\t0.178\n",
       "F.N. cost:\t0.576\n",
       "Base rate:\t0.378\n",
       "Avg. score:\t0.271"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cauc_test_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy:\t0.592\n",
       "F.P. cost:\t0.207\n",
       "F.N. cost:\t0.585\n",
       "Base rate:\t0.531\n",
       "Avg. score:\t0.318"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_afr_am_test_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy:\t0.691\n",
       "F.P. cost:\t0.136\n",
       "F.N. cost:\t0.594\n",
       "Base rate:\t0.378\n",
       "Avg. score:\t0.238"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cauc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy:\t0.688\n",
       "F.P. cost:\t0.316\n",
       "F.N. cost:\t0.307\n",
       "Base rate:\t0.531\n",
       "Avg. score:\t0.516"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_afr_am_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What notion of fairness does this method achieve, if any? What is the effect of this method on the accuracy? Do you think we should use this method for our pre-trial bail application?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fair Reductions\n",
    "\n",
    "Now we will consider a different fairness algorithm developed by "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fairlearn.moments as moments\n",
    "import fairlearn.classred as red\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Their method will "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(C=100000, max_iter=10000, solver = \"lbfgs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(train[:, np.r_[0:7, 11:13]])#pd.DataFrame(train[:, :-2])\n",
    "A = pd.Series(train[:,feat_map.index('race_African-American')])\n",
    "Y = pd.Series(train[:,-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We call the method expgrad (which stands for exponentiated gradient) to learn the fair algorithm. We specify cons=moments.EO() for equalized odds (or if we wanted demographic partity then we would specify moments.DP()). eps is the allowable error tolerance in the fairness goal. As we decrease eps toward 0, we should get closer to the fairness target. As we increase eps away from 0, we would expect to have a more accurate classifier that is farther from the fairness target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_tuple = red.expgrad(dataX = X, dataA = A, dataY = Y, learner=logreg, cons=moments.EO(), eps=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = res_tuple._asdict()\n",
    "Q = res[\"best_classifier\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q is the best classifier learned by this method. We can all Q(dat) where dat is a pandas dataframe containing our covariates. This will return a pandas Series with the predicted probabilities. \n",
    "\n",
    "Does this achieve equalized odds?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "African-American tpr: 0.19115. Caucasian tpr: 0.23286\n",
      "African-American fpr: 0.19006. Caucasian fpr: 0.33333\n"
     ]
    }
   ],
   "source": [
    "tpr_afr_am = Q(X)[np.logical_and(A==1, Y==1)].round().mean()\n",
    "tpr_cauc = Q(X)[np.logical_and(A==0, Y==1)].round().mean()\n",
    "fpr_afr_am = Q(X)[np.logical_and(A==1, Y==0)].round().mean()\n",
    "fpr_cauc = Q(X)[np.logical_and(A==0, Y==0)].round().mean()\n",
    "print(\"African-American tpr: {0:.5f}. Caucasian tpr: {1:.5f}\".format(tpr_afr_am, tpr_cauc))\n",
    "print(\"African-American fpr: {0:.5f}. Caucasian fpr: {1:.5f}\".format(fpr_afr_am, fpr_cauc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5071563597083446"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Q(X).round() != Y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4487359537976658"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Q(X) - Y).abs().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a slight problem with the calculations we just did. What is the problem? *Hint* can you use X_test (created in the next line) to solve this problem? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.DataFrame(test[:, :-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[1, feat_map.index('sex_Female')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4487359537976658"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = moments.MisclassError()\n",
    "error.init(X, A, Y)\n",
    "error.gamma(Q)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2784825480993945\n",
      "0.27655390253500134\n",
      "0.2775539023955563\n",
      "0.190625\n",
      "0.2938867077958497\n",
      "0.24034566567647853\n"
     ]
    }
   ],
   "source": [
    "print(Q(X)[A==1].mean())\n",
    "print(Q(X)[A==0].mean())\n",
    "print(Q(X).mean())\n",
    "\n",
    "print(Q(X)[A==1].round().mean())\n",
    "print(Q(X)[A==0].round().mean())\n",
    "print(Q(X).round().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28.,  0.,  0.,  0., 57.,  1.,  0.,  0.,  1.])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[100, np.r_[0:7, 11:13]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[10, -2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "attrs = [str(x) for x in 'AAAAAAA' 'BBBBBBB']\n",
    "labls = [int(x) for x in '0110100' '0010111']\n",
    "feat1 = [int(x) for x in '0110101' '0111101']\n",
    "feat2 = [int(x) for x in '0000100' '0000011']\n",
    "feat3 = [int(x) for x in '1111111' '1111111']\n",
    "\n",
    "dataX = pd.DataFrame({\"feat1\": feat1, \"feat2\": feat2, \"feat3\": feat3})\n",
    "dataY = pd.Series(labls)\n",
    "dataA = pd.Series(attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_tuple2 = red.expgrad(dataX, dataA, dataY, learner=logreg, cons=moments.DP(), eps=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "res2 = res_tuple2._asdict()\n",
    "q = res_tuple2._asdict()['best_classifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.00199999956032737"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q(dataX)[dataA == 'A'].mean()-q(dataX)[dataA == 'B'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.502499999451681"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q(dataX)[dataA == 'B'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.0009999997801637406"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7     2.131304e-01\n",
       "8     4.402609e-01\n",
       "9     4.402609e-01\n",
       "10    4.402609e-01\n",
       "11    4.402609e-01\n",
       "12    1.098689e-08\n",
       "13    7.868696e-01\n",
       "dtype: float64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q(dataX)[dataA == 'B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.4965\n",
       "1     0.5035\n",
       "2     0.5035\n",
       "3     0.4965\n",
       "4     0.5035\n",
       "5     0.4965\n",
       "6     0.5035\n",
       "7     0.4965\n",
       "8     0.5035\n",
       "9     0.5035\n",
       "10    0.5035\n",
       "11    0.5035\n",
       "12    0.5035\n",
       "13    0.5035\n",
       "dtype: float64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q(dataX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.0\n",
       "1     1.0\n",
       "2     1.0\n",
       "3     0.0\n",
       "4     1.0\n",
       "5     0.0\n",
       "6     1.0\n",
       "7     0.0\n",
       "8     1.0\n",
       "9     1.0\n",
       "10    1.0\n",
       "11    1.0\n",
       "12    1.0\n",
       "13    1.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q(dataX).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = moments.DP()\n",
    "disp.init(dataX, dataA, dataY)\n",
    "res2[\"disp\"] = disp.gamma(q).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 3)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('best_classifier',\n",
       "              <function fairlearn.classred.expgrad.<locals>.<lambda>(X)>),\n",
       "             ('best_gap', 4.396726316358013e-10),\n",
       "             ('classifiers',\n",
       "              0    LogisticRegression(C=100000, class_weight=None...\n",
       "              1    LogisticRegression(C=100000, class_weight=None...\n",
       "              dtype: object),\n",
       "             ('weights', 0    0.5035\n",
       "              1    0.4965\n",
       "              dtype: float64),\n",
       "             ('last_t', 5),\n",
       "             ('best_t', 5),\n",
       "             ('n_oracle_calls', 17),\n",
       "             ('disp', 0.0009999997801637406)])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res_tuple3 = red.expgrad(dataX, dataA, dataY, learner=logreg, cons=moments.EO(), eps=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res3 = res_tuple3._asdict()\n",
    "q3 = res3['best_classifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q3(dataX)[np.logical_and(dataA=='A',dataY == 1)].round().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q3(dataX)[np.logical_and(dataA=='B',dataY == 1)].round().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5720000029208396"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q3(dataX)[np.logical_and(dataA=='A',dataY == 1)].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5895000016750881"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q3(dataX)[np.logical_and(dataA=='B',dataY == 1)].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.007499999466106577"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q3(dataX)[dataY == 1].mean()- q3(dataX)[np.logical_and(dataA=='B',dataY == 1)].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.009999999288141881"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q3(dataX)[dataY == 1].mean()- q3(dataX)[np.logical_and(dataA=='A',dataY == 1)].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.07142857142857145"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q3(dataX)[dataY == 1].round().mean()- q3(dataX)[np.logical_and(dataA=='B',dataY == 1)].round().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "disp3 = moments.DP()\n",
    "disp3.init(dataX, dataA, dataY)\n",
    "res3[\"disp\"] = disp3.gamma(q3).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('best_classifier',\n",
       "              <function fairlearn.classred.expgrad.<locals>.<lambda>(X)>),\n",
       "             ('best_gap', 1.1009944067552624e-09),\n",
       "             ('classifiers',\n",
       "              0    LogisticRegression(C=100000, class_weight=None...\n",
       "              1    LogisticRegression(C=100000, class_weight=None...\n",
       "              2    LogisticRegression(C=100000, class_weight=None...\n",
       "              3    LogisticRegression(C=100000, class_weight=None...\n",
       "              4    LogisticRegression(C=100000, class_weight=None...\n",
       "              5    LogisticRegression(C=100000, class_weight=None...\n",
       "              dtype: object),\n",
       "             ('weights', 0    4.907486e-09\n",
       "              1    3.160000e-01\n",
       "              2    3.260000e-01\n",
       "              3    1.806719e-09\n",
       "              4    3.580000e-01\n",
       "              5    1.368589e-09\n",
       "              dtype: float64),\n",
       "             ('last_t', 5),\n",
       "             ('best_t', 5),\n",
       "             ('n_oracle_calls', 23),\n",
       "             ('disp', 0.026285713600953553)])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
